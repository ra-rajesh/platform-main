name: Terraform Destroy

on:
  workflow_dispatch:
    inputs:
      env:
        description: Environment
        required: true
        type: choice
        options: [dev, stage, prod]
        default: stage
      stack:
        description: Stack to destroy (all or a single stack)
        required: true
        type: choice
        options: [all, cloudwatch, rest-api, ssm, nlb, compute, ecr, s3, network]
        default: all

concurrency:
  group: tf-destroy-${{ inputs.env }}-${{ inputs.stack }}-${{ github.ref_name }}
  cancel-in-progress: false

jobs:
  destroy:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    env:
      AWS_REGION: ap-south-1
      TF_IN_AUTOMATION: "true"
      AWS_ACCESS_KEY_ID_DEV:       ${{ secrets.AWS_ACCESS_KEY_ID_DEV }}
      AWS_SECRET_ACCESS_KEY_DEV:   ${{ secrets.AWS_SECRET_ACCESS_KEY_DEV }}
      AWS_ACCESS_KEY_ID_STAGE:     ${{ secrets.AWS_ACCESS_KEY_ID_STAGE }}
      AWS_SECRET_ACCESS_KEY_STAGE: ${{ secrets.AWS_SECRET_ACCESS_KEY_STAGE }}
      AWS_ACCESS_KEY_ID_PROD:      ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}
      AWS_SECRET_ACCESS_KEY_PROD:  ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}

    steps:
      - uses: actions/checkout@v4

      - name: Select AWS access keys for env
        shell: bash
        run: |
          case "${{ inputs.env }}" in
            dev)
              echo "AWS_ACCESS_KEY_ID=${{ env.AWS_ACCESS_KEY_ID_DEV }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ env.AWS_SECRET_ACCESS_KEY_DEV }}" >> $GITHUB_ENV
              ;;
            stage)
              echo "AWS_ACCESS_KEY_ID=${{ env.AWS_ACCESS_KEY_ID_STAGE }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ env.AWS_SECRET_ACCESS_KEY_STAGE }}" >> $GITHUB_ENV
              ;;
            prod)
              echo "AWS_ACCESS_KEY_ID=${{ env.AWS_ACCESS_KEY_ID_PROD }}" >> $GITHUB_ENV
              echo "AWS_SECRET_ACCESS_KEY=${{ env.AWS_SECRET_ACCESS_KEY_PROD }}" >> $GITHUB_ENV
              ;;
          esac

      - name: Configure AWS credentials (access keys)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.9.5

      - name: Destroy stacks in safe order
        shell: bash
        run: |
          set -euo pipefail

          ENV="${{ inputs.env }}"
          SEL="${{ inputs.stack }}"

          # Safe destroy order (downstream first)
          ORDER=( cloudwatch rest-api ssm nlb compute ecr s3 network )
          if [[ "$SEL" != "all" ]]; then ORDER=("$SEL"); fi

          for S in "${ORDER[@]}"; do
            WD="infra/environments/${ENV}/stacks/${S}"
            if [[ ! -d "$WD" ]]; then
              echo "::warning::Skipping $WD (not found)"
              continue
            fi
            if [[ ! -f "${WD}/backend-${ENV}.hcl" ]]; then
              echo "::error::Missing ${WD}/backend-${ENV}.hcl"
              exit 1
            fi

            # ðŸ§¹ Extra cleanup ONLY for the 'compute' stack:
            # Delete orphaned instance profile/role so TF doesn't hit EntityAlreadyExists
            if [[ "$S" == "compute" ]]; then
              echo "=== CLEANUP: IAM instance profile/role (${ENV})"
              PROFILE_NAME="${ENV}-ec2-ssm-instance-profile"
              ROLE_NAME="${ENV}-ec2-ssm-role"

              # If profile exists, detach any EC2 associations, remove role from profile, then delete profile
              if aws iam get-instance-profile --instance-profile-name "$PROFILE_NAME" >/dev/null 2>&1; then
                echo "Found instance profile: $PROFILE_NAME"

                ACCOUNT_ID="$(aws sts get-caller-identity --query Account --output text)"
                PROFILE_ARN="arn:aws:iam::${ACCOUNT_ID}:instance-profile/${PROFILE_NAME}"

                # Disassociate from any instances (region-specific call)
                ASSOC_IDS="$(aws ec2 describe-iam-instance-profile-associations \
                  --region "${AWS_REGION}" \
                  --filters Name=iam-instance-profile.arn,Values="${PROFILE_ARN}" \
                  --query 'IamInstanceProfileAssociations[].AssociationId' \
                  --output text || true)"
                for AID in $ASSOC_IDS; do
                  echo "Disassociating instance profile: $AID"
                  aws ec2 disassociate-iam-instance-profile --region "${AWS_REGION}" --association-id "$AID" || true
                done

                # Remove any attached roles from the profile
                ROLE_NAMES="$(aws iam get-instance-profile \
                  --instance-profile-name "$PROFILE_NAME" \
                  --query 'InstanceProfile.Roles[].RoleName' \
                  --output text || true)"
                for RN in $ROLE_NAMES; do
                  echo "Removing role $RN from instance profile $PROFILE_NAME"
                  aws iam remove-role-from-instance-profile \
                    --instance-profile-name "$PROFILE_NAME" \
                    --role-name "$RN" || true
                done

                echo "Deleting instance profile: $PROFILE_NAME"
                aws iam delete-instance-profile --instance-profile-name "$PROFILE_NAME" || true
              else
                echo "Instance profile not present: $PROFILE_NAME (nothing to delete)"
              fi

              # Optionally delete the role too (safe if it exists)
              if aws iam get-role --role-name "$ROLE_NAME" >/dev/null 2>&1; then
                echo "Cleaning up role: $ROLE_NAME"

                # Detach managed policies
                for P in $(aws iam list-attached-role-policies --role-name "$ROLE_NAME" \
                          --query 'AttachedPolicies[].PolicyArn' --output text || true); do
                  echo "Detaching $P from $ROLE_NAME"
                  aws iam detach-role-policy --role-name "$ROLE_NAME" --policy-arn "$P" || true
                done

                # Delete inline policies
                for IP in $(aws iam list-role-policies --role-name "$ROLE_NAME" \
                          --query 'PolicyNames[]' --output text || true); do
                  echo "Deleting inline policy $IP from $ROLE_NAME"
                  aws iam delete-role-policy --role-name "$ROLE_NAME" --policy-name "$IP" || true
                done

                echo "Deleting role: $ROLE_NAME"
                aws iam delete-role --role-name "$ROLE_NAME" || true
              else
                echo "Role not present: $ROLE_NAME (nothing to delete)"
              fi
            fi

            TFVARS_FLAG=""
            if [[ -f "${WD}/${ENV}.tfvars" ]]; then
              TFVARS_FLAG="-var-file=${ENV}.tfvars"
            else
              echo "::notice::No ${WD}/${ENV}.tfvars; relying on defaults/vars"
            fi

            echo "=== INIT: $WD"
            terraform -chdir="$WD" init -input=false -reconfigure -backend-config="backend-${ENV}.hcl"

            echo "=== PLAN (destroy): $WD"
            terraform -chdir="$WD" plan -destroy -input=false $TFVARS_FLAG -var="env_name=${ENV}" -out=tfplan

            echo "=== DESTROY: $WD"
            terraform -chdir="$WD" apply -input=false -auto-approve tfplan || {
              echo "::error::Destroy failed for $WD"
              exit 1
            }
          done
